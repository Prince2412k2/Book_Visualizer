{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DOCUMENTATION\n",
    "___\n",
    "## **LLM**\n",
    "\n",
    "| **Model**                    | **Context Window** |**Limits**           |\n",
    "|------------------------------|--------------------|---------------------|\n",
    "| **Qwen 2.5 35B Code**        | Up to 128K tokens  |Fine Tuned for coding|\n",
    "| **Cohere Command R+**        | Up to 128K tokens  | 1000 calls per month|\n",
    "| **Mistral-7B-Instruct-v0.3** | 32,768 tokens      | Hallucinations      |\n",
    "\n",
    "#### Using `Mistral-7B-Instruct-v0.3` because \n",
    "- reliable outputs\n",
    "- 1000 calls per day\n",
    "- works in huggingface(same as text-to-image)\n",
    "\n",
    "\n",
    "## **Text-to-Image**\n",
    "\n",
    "\n",
    "| **Category**               | **Stable Diffusion 3.5 Large Turbo**                                                                 | **FLUX.1-Dev FP16**                                                                       |\n",
    "|----------------------------|-----------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------|\n",
    "| **API Endpoint**           | `stabilityai/stable-diffusion-3-5-large-turbo`                                                     | `black-forest-labs/FLUX.1-Dev-FP16`                                                     |\n",
    "| **Key API Parameters**     | `guidance_scale=3`, `num_inference_steps=4`, `negative_prompt`                                     | `num_inference_steps=8`, `control_image` (Canny/Depth), `true_cfg=4.0`                  |\n",
    "| **API Latency**            | 3.8–5.2 sec/image (cold start: 12–18 sec)                                                          | 6.1–8.9 sec/image (cold start: 15–22 sec)                                                |\n",
    "| **Cost Efficiency**        | $0.0021/image (PRO tier)                                                                           | $0.0033/image (PRO tier)                                                                 |\n",
    "| **Free Tier Limits**       | 500 requests/hour                                                                                  | 300 requests/hour                                                                        |\n",
    "| **Max Resolution**         | 1024x1024 via single API call                                                                      | 2048x2048 (requires `high_res_fix=true` parameter)                                       |\n",
    "| **Advanced Features**      | - 4-step inference <br> - Text-to-image only                                                       | - Unified ControlNet (Canny/Depth) <br> - Image-to-image <br> - Inpainting/Outpainting   |\n",
    "| **NSFW Filtering**         | Enabled by default (`safety_checker=strict`)                                                       | Optional (`safety_checker=relaxed`)                                                      |\n",
    "| **Rate Limits (PRO)**      | 5K requests/hour                                                                                   | 3K requests/hour                                                                         |\n",
    "| **Use Case Focus**         | Rapid batch generation (social media, prototyping)                                                 | High-detail workflows (product design, architectural viz)                                |\n",
    "\n",
    "#### using `SD-3.5-LT` because \n",
    "- latency is low\n",
    "- More requests\n",
    "- we want stialized images which is better on SD \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reader import ebook\n",
    "from main import read_list,read_json\n",
    "from typing import Optional,Dict,List\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import os\n",
    "from pydantic import BaseModel, conint\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "API = os.getenv(\"HF_API\")\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {API}\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "}\n",
    "url = \"https://api-inference.huggingface.co/models/mistralai/Mistral-7B-Instruct-v0.3/v1/chat/completions\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "___\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get **Summary**, **Characters** AND **Places** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Local Image](/home/prince/Documents/Project/BOOK/media/Sudo_summary.png \"Smmary, characters and Places\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_role='''(NOTE: Only output in JSON. Ensure the JSON format is valid, well-formed, and Ready to parse. nothing before or after the json file)\n",
    "Input:  \n",
    "1.Current Chapter Text: The current chapter to be analyzed.\n",
    "2.Character List: A list of characters with their physical/visual descriptions till now (This chapter).\n",
    "3.Places list: list of places and their visual description till now (This chapter).\n",
    "4.Previous Chapters' Summary: Context from earlier chapters.\n",
    "\n",
    "Rules:  \n",
    "1.Narrative Summary: Summarize and explain the chapter in detail, integrating context and key developments from previous chapters and create a self containing summary and explaination. end with to be continued.\n",
    "2.Character List: add new characters to the list based on this chapter and Update existing character's physical/visual descriptions. If no characters are mentioned, return the same list as given.\n",
    "3.Places: Include an updated description of any significant locations mentioned in this chapter, focusing on environment, weather, vibe, and structure.\n",
    "4.Output Format: Ensure the output is valid and well-structured JSON.\n",
    "\n",
    "Output:  \n",
    "Generate a JSON object in this format:\n",
    "{\n",
    "  \"summary\": \"Detailed Summary and explination of the current chapter in context of previous chapters. Use previus chapter summary as context\",\n",
    "  \"characters\": {\n",
    "      \"Character Name\": \"Updated or new physical/visual description (age, looks, clothes, hair, body language) based on this chapter.\"\n",
    "    },\n",
    "  \"places\": {\n",
    "      \"Place Name\": \"Updated or new visual description (environment, weather, vibe, structure, etc.) based on this chapter.\"\n",
    "  }\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **get_sum()** Function\n",
    "![Local Image](/home/prince/Documents/Project/BOOK/media/Get_sum_logic.png \"Smmary, characters and Places\")\n",
    "\n",
    "\n",
    "outputdir=\n",
    "```{\n",
    "    0:\n",
    "        {\n",
    "            \"summary\":\"No previous Context Yet\",\n",
    "            \"characters\":{},\n",
    "            \"places\": {}\n",
    "        }\n",
    "            }```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class SummarySchema(BaseModel):\n",
    "    summary: str\n",
    "    characters: Dict[str,str]\n",
    "    places: Dict[str,str]\n",
    "\n",
    "def sum_msg(text: str, context: str, characters: dict = {}, places: dict = {}) -> list:\n",
    "    message = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": sum_role\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": json.dumps({\n",
    "                \"past_context\": context,\n",
    "                \"Current_Chapter\": text,\n",
    "                \"character_list\": characters,\n",
    "                \"places_list\": places\n",
    "            }),\n",
    "        },\n",
    "    ]\n",
    "    return message\n",
    "\n",
    "def get_summ(messages:Dict[str,str]) -> Optional[str]:\n",
    "    data = {\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": 0.7,\n",
    "        \"stream\": False,\n",
    "        \"max_tokens\":10000,\n",
    "        \"parameters\": {\n",
    "        \"repetition_penalty\": 1.3,\n",
    "        \"grammar\": {\n",
    "            \"type\": \"json\",\n",
    "            \"value\": SummarySchema.model_json_schema()\n",
    "                }\n",
    "                    }\n",
    "    }\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        response_data = response.json()\n",
    "        assistant_message = response_data[\"choices\"][0][\"message\"][\"content\"]\n",
    "        return assistant_message\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}, {response.text}\")\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# book=ebook(\"./books/Alchemist/Alchemist.epub\")\n",
    "book=ebook(\"./books/LP.epub\")\n",
    "title=book.get_metadata()['title']\n",
    "_,text=zip(*book.get_chapters())\n",
    "text=text[:3]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict={\n",
    "    0:\n",
    "        {\n",
    "            \"summary\":\"There is no previous context\",\n",
    "            \"characters\":{},\n",
    "            \"places\": {}\n",
    "        }\n",
    "            }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx,i in enumerate(text):\n",
    " \n",
    "    if len(i)<1200:\n",
    "        output_dict[idx+1]=output_dict[idx]\n",
    "    else:\n",
    "        context=output_dict[idx][\"summary\"]\n",
    "        characters=output_dict[idx][\"characters\"]\n",
    "        places=output_dict[idx][\"places\"]\n",
    "        \n",
    "        mes=sum_msg(i,context,characters,places)\n",
    "        \n",
    "        summary_characters=get_summ(mes)\n",
    "        output_json=read_json(summary_characters)\n",
    "        output_dict[idx+1]=output_json\n",
    "    print(f\"chapter: {idx} done\")\n",
    "print(output_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num, dic in output_dict.items():\n",
    "    if num==0:\n",
    "        continue\n",
    "    print(f\"CHAPTER {num} :\\n\")\n",
    "    \n",
    "    sum,char,places=dic.items()\n",
    "    print(\"Characters:\")\n",
    "    if len(char)>0 :\n",
    "        for name,i in char[1].items():\n",
    "            print(f\"{name}: {i}\")\n",
    "    \n",
    "    print(\"\\nPlaces:\")\n",
    "    if len(places)>0:\n",
    "        for name,i in places[1].items():\n",
    "            print(f\"{name}: {i}\")\n",
    "    print(f\"\\nSummary:\\n{sum[1]}\")\n",
    "    print(\"\\n-------------------------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "___\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get **Scenes**\n",
    "![Local Image](/home/prince/Documents/Project/BOOK/media/Sudo_summary.png )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SceneSchema(BaseModel):\n",
    "    scenes: Dict[str,str]\n",
    "print(SceneSchema.model_json_schema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scene_msg(text: str) -> list:\n",
    "    message = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": ''' IMPORTANT-> ONLY OUTPUT IN JSON.\n",
    "                You are a text-to-image prompt generator for for book visulizer.\n",
    "                Your task is to analyze the provided input text and identify distinct scenes where there are changes in place or time. \n",
    "                For each identified scene, create a detailed and descriptive prompt suitable for generating an image.\n",
    "                Only Consider a Scene change if there is a change in time place or characters.\n",
    "                only include visual info. dont go into details.\n",
    "                \n",
    "                Characters: Refer to characters by their respective names as mentioned in the text.\n",
    "                Places: Refer to places by their proper names as mentioned in the text.\n",
    "                Ensure each prompt captures the scene's mood, setting, and key visual elements.\n",
    "                \n",
    "                1. **Input:**\n",
    "                    - `text`: A block of narrative text.```\n",
    "                2. **Output:**\n",
    "                    - {\n",
    "                        \"scene1\":\"prompt1\",\n",
    "                        \"scene2\":\"prompt2\",\n",
    "                        ...\n",
    "                    }\n",
    "\n",
    "                ### Instructions:\n",
    "                - Identify key changes in location, characters, or significant actions to define separate scenes.\n",
    "                - Use descriptive language to paint a vivid picture of each scene in the prompt.\n",
    "                \n",
    "                   ''',\n",
    "        },\n",
    "        \n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"TEXT: {text}\"\"\",  # This should be your input text that describes the scenes\n",
    "        },]\n",
    "        \n",
    "    return message\n",
    "\n",
    "def get_scene(scene_msg: list) -> Optional[str]:\n",
    "    data = {\n",
    "        \"messages\": scene_msg,\n",
    "        \"max_tokens\": 10000,  # Specify the maximum length of the response\n",
    "        \"temperature\": 0,  # Control the randomness of the response\n",
    "        \"stream\": False,\n",
    "        \"repetition_penalty\": 1.3,\n",
    "        \"grammar\": {\n",
    "            \"type\": \"json\",\n",
    "            \"value\": SceneSchema.model_json_schema()\n",
    "                }\n",
    "        }\n",
    "    \n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "\n",
    "    # Check the response status code and process the output\n",
    "    if response.status_code == 200:\n",
    "        response_data = response.json()\n",
    "        # Extract the assistant's message content\n",
    "        assistant_message = response_data[\"choices\"][0][\"message\"][\"content\"]\n",
    "        return assistant_message\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}, {response.text}\")  # Print error details\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_output_list=[]\n",
    "print(\"--Genrating Scenes per chapter--\")\n",
    "for idx,i in enumerate(text):\n",
    "    inputs=i.replace(\"\\n\",\" \")\n",
    "    scene_message = scene_msg(text)\n",
    "    scene_output=get_scene(scene_message)\n",
    "    scene_json_output=read_json(scene_output)\n",
    "    scene_output_list.append(scene_json_output)\n",
    "    print(f\"chapter: {idx+1} Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_output_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "___\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get **Style**\n",
    "![Local Image](/home/prince/Documents/Project/BOOK/media/Get_Style_logic.png )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_llm_req(text: str) -> Optional[str]:\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\":\"system\",\n",
    "            \"content\":\"DO As Asked in The Input\"\n",
    "        },\n",
    "        {\n",
    "            \"role\":\"user\",\n",
    "            \"content\":text\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    data = {\n",
    "        \"messages\": messages,\n",
    "        \"max_tokens\": 10000,  # Specify the maximum length of the response\n",
    "        \"temperature\": 0,  # Control the randomness of the response\n",
    "        \"stream\": False,\n",
    "    }\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "\n",
    "    # Check the response status code and process the output\n",
    "    if response.status_code == 200:\n",
    "        response_data = response.json()\n",
    "        # Extract the assistant's message content\n",
    "        assistant_message = response_data[\"choices\"][0][\"message\"][\"content\"]\n",
    "        return assistant_message\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}, {response.text}\")  # Print error details\n",
    "        return None\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_summary=\"\"\n",
    "for key,val in output_dict.items():\n",
    "    val_content=val[\"summary\"].replace(\"\\n\",\" \")\n",
    "    if key==0:\n",
    "        continue\n",
    "    output_string= f'''{combined_summary}... Chapter{key}: {val_content}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_prompt='''Prompt:\n",
    "Note - dont give more than asked for. \n",
    "\"Analyze the following story and provide a list of image style tags that would best suit its themes, settings, and overall mood. \n",
    "The response should include the style, period, type of art, color palette etc. 1 tags per entry.\n",
    "dont explain it just give tags.\n",
    "\n",
    "**ONLY TAGS**\n",
    "\n",
    "Response Format:\n",
    "\n",
    "Style: Realism or Impressionism or Surrealism oretc\n",
    "Type:Landscape, Portrait or Abstract or etc.\n",
    "Color Palette:Warm tones or Cool colors or Monochromatic or black and white or etc\n",
    "Mood:Serene or Dramatic or Melancholic or etc.\n",
    "\n",
    "reuired:(Style,Type,Color_palette,Mood)\n",
    "Story\n",
    "'''\n",
    "\n",
    "style=basic_llm_req(f'''{style_prompt}:{combined_summary} ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get **Image**\n",
    "![Local Image](/home/prince/Documents/Project/BOOK/media/Get_img_logic.png )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "import time\n",
    "\n",
    "client = InferenceClient(\n",
    "    \"stabilityai/stable-diffusion-3.5-large-turbo\",\n",
    "    token=API,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(key, text,tag,characters,places,style):\n",
    "    image = client.text_to_image(\n",
    "        f\"Text: {text}// context-> characters: {characters}, places:{places} // style:{style} \",\n",
    "        negative_prompt=\"hand,feet,text,written,shinny,artificial,unnatural,plastic,words,letters\",\n",
    "        height=1024,\n",
    "        width= 1024,\n",
    "        guidance_scale=2,\n",
    "        num_inference_steps=10\n",
    "        \n",
    "    )\n",
    "    image.save(f\"./output/{title}_{key}_{tag}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs=[]\n",
    "outputs=[[val for key,val in chapter_prompt.items()] for chapter_prompt in scene_output_list]\n",
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop Logic\n",
    "![Local Image](/home/prince/Documents/Project/BOOK/media/Image_Loop.png )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for idx,i in enumerate(outputs):\n",
    "    chars=output_dict[idx+1][\"characters\"]\n",
    "    places=output_dict[idx+1][\"places\"]\n",
    "    for jdx,j in enumerate(i):\n",
    "        ##try except for internal server error\n",
    "        try:\n",
    "            key=f\"C{idx}S{jdx+1}\"\n",
    "            text=j\n",
    "            tag=\"\"\n",
    "            get_images(key=key,text=text,tag=tag,characters=chars,places=places,style=style)\n",
    "            print(f\"{key} saved. tag : {tag} \")\n",
    "            print(f\"    prompt:{text} \\n    characters:{chars}\\n    places:{places}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error while calling the API :{e} \\n waiting for 10 seconds.. \")\n",
    "            time.sleep(10)\n",
    "            get_images(key=key,text=text,tag=tag,characters=chars,places=places,style=style)\n",
    "            print(f\"{key} saved. tag : {tag} \")\n",
    "            print(f\"    prompt:{text}\")\n",
    "\n",
    "        time.sleep(18)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "book",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
