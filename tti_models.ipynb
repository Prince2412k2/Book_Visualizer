{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [text-to-img](./Model_lists/text-to-image.md)\n",
    "\n",
    "## Prompt- \n",
    "#### A rocky surface under a starry night sky. A small boy with golden hair sits holding a box, gazing at it thoughtfully. A pilot stands nearby, observing the boy. Distant planets glow faintly in the background.//Style - landscape\n",
    "\n",
    "| Model Name                                      | Link                                                                           | Time      | Image                                                              |\n",
    "| ----------------------------------------------- | ------------------------------------------------------------------------------ | --------- | ------------------------------------------------------------------ |\n",
    "| strangerzonehf/Qs-Sketch                        | [Link](https://huggingface.co/strangerzonehf/Qs-Sketch)                        | 2.03 mins | ![img](Images/strangerzonehf_Qs-Sketch.png)                        |\n",
    "| black-forest-labs/flux.1-dev                    | [Link](https://huggingface.co/black-forest-labs/FLUX.1-dev)                    | 36.95 sec | ![img](Images/black-forest-labs_flux.1-dev.png)                    |\n",
    "| black-forest-labs/FLUX.1-schnell                | [Link](https://huggingface.co/black-forest-labs/FLUX.1-schnell)                | 28.94 sec | ![img](Images/black-forest-labs_FLUX.1-schnell.png)                |\n",
    "| CompVis/stable-diffusion-v1-4                   | [Link](https://huggingface.co/CompVis/stable-diffusion-v1-4)                   | 5.86 sec  | ![img](Images/CompVis_stable-diffusion-v1-4.png)                   |\n",
    "| digiplay/aurorafantasy_v1                       | [Link](https://huggingface.co/digiplay/aurorafantasy_v1)                       | 8.53 sec  | ![img](Images/digiplay_aurorafantasy_v1.png)                       |\n",
    "| digiplay/Blazarot_blazaroshi                    | [Link](https://huggingface.co/digiplay/Blazarot_blazaroshi)                    | 41.41 sec | ![img](Images/digiplay_Blazarot_blazaroshi.png)                    |\n",
    "| digiplay/darkphoenix3D_v1.1                     | [Link](https://huggingface.co/digiplay/darkphoenix3D_v1.1)                     | 1.91 mins | ![img](Images/digiplay_darkphoenix3D_v1.1.png)                     |\n",
    "| digiplay/PerfectDeliberate-Anime_v2             | [Link](https://huggingface.co/digiplay/PerfectDeliberate-Anime_v2)             | 1.41 mins | ![img](Images/digiplay_PerfectDeliberate-Anime_v2.png)             |\n",
    "| digiplay/Photon_v1                              | [Link](https://huggingface.co/digiplay/Photon_v1)                              | 11.25 sec | ![img](Images/digiplay_Photon_v1.png)                              |\n",
    "| digiplay/rRealism_v1.0_riiwa                    | [Link](https://huggingface.co/digiplay/rRealism_v1.0_riiwa)                    | 1.28 mins | ![img](Images/digiplay_rRealism_v1.0_riiwa.png)                    |\n",
    "| digiplay/ya3_xt                                 | [Link](https://huggingface.co/digiplay/ya3_xt)                                 | 10.15 sec | ![img](Images/digiplay_ya3_xt.png)                                 |\n",
    "| Niggendar/duchaitenPonyXLNo_v35                 | [Link](https://huggingface.co/Niggendar/duchaitenPonyXLNo_v35)                 | 2.26 mins | ![img](Images/Niggendar_duchaitenPonyXLNo_v35.png)                 |\n",
    "| stabilityai/stable-diffusion-2                  | [Link](https://huggingface.co/stabilityai/stable-diffusion-2)                  | 2.66 mins | ![img](Images/stabilityai_stable-diffusion-2.png)                  |\n",
    "| stabilityai/stable-diffusion-3-medium-diffusers | [Link](https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers) | 12.43 sec | ![img](Images/stabilityai_stable-diffusion-3-medium-diffusers.png) |\n",
    "| stabilityai/stable-diffusion-3.5-large          | [Link](https://huggingface.co/stabilityai/stable-diffusion-3.5-large)          | 16.49 sec | ![img](Images/stabilityai_stable-diffusion-3.5-large.png)          |\n",
    "| stabilityai/stable-diffusion-3.5-large-turbo    | [Link](https://huggingface.co/stabilityai/stable-diffusion-3.5-large-turbo)    | 1.85 sec  | ![img](Images/stabilityai_stable-diffusion-3.5-large-turbo.png)    |\n",
    "| stabilityai/stable-diffusion-xl-base-1.0        | [Link](https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0)        | 8.00 sec  | ![img](Images/stabilityai_stable-diffusion-xl-base-1.0.png)        |\n",
    "| stable-diffusion-v1-5/stable-diffusion-v1-5     | [Link](https://huggingface.co/stable-diffusion-v1-5/stable-diffusion-v1-5)     | 13.28 sec | ![img](Images/stable-diffusion-v1-5_stable-diffusion-v1-5.png)     |\n",
    "| Yntec/epiCPhotoGasm                             | [Link](https://huggingface.co/Yntec/epiCPhotoGasm)                             | 25.40 sec | ![img](Images/Yntec_epiCPhotoGasm.png)                             |\n",
    "| Yntec/ICantBelieveItSNotPhotography             | [Link](https://huggingface.co/Yntec/ICantBelieveItSNotPhotography)             | 1.05 mins | ![img](Images/Yntec_ICantBelieveItSNotPhotography.png)             |\n",
    "| Yntec/IncredibleLife                            | [Link](https://huggingface.co/Yntec/IncredibleLife)                            | 8.84 sec  | ![img](Images/Yntec_IncredibleLife.png)                            |\n",
    "| Yntec/IncredibleWorld                           | [Link](https://huggingface.co/Yntec/IncredibleWorld)                           | 37.60 sec | ![img](Images/Yntec_IncredibleWorld.png)                           |\n",
    "| Yntec/IncredibleWorld2                          | [Link](https://huggingface.co/Yntec/IncredibleWorld2)                          | 8.87 sec  | ![img](Images/Yntec_IncredibleWorld2.png)                          |\n",
    "| Yntec/TrueSight                                 | [Link](https://huggingface.co/Yntec/TrueSight)                                 | 8.44 sec  | ![img](Images/Yntec_TrueSight.png)                                 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "___\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEXT-TO-IMG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time-Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import signal\n",
    "import time\n",
    "from functools import wraps\n",
    "\n",
    "# Define a timeout exception\n",
    "class TimeoutError(Exception):\n",
    "    pass\n",
    "\n",
    "# Signal handler for timeout\n",
    "def timeout_handler(signum, frame):\n",
    "    raise TimeoutError(\"Function execution timed out\")\n",
    "\n",
    "# Decorator to limit function execution time\n",
    "def timeout_decorator(time_limit):\n",
    "    def decorator(func):\n",
    "        @wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            # Set the signal handler and alarm\n",
    "            signal.signal(signal.SIGALRM, timeout_handler)\n",
    "            signal.alarm(time_limit)  # Set the alarm for `time_limit` seconds\n",
    "\n",
    "            try:\n",
    "                result = func(*args, **kwargs)  # Execute the function\n",
    "                signal.alarm(0)  # Disable the alarm if the function completes in time\n",
    "                return result  # Return the result of the function\n",
    "            except TimeoutError:\n",
    "                return 180,\">3 mins\"  # Return the string if the function exceeds the time limit\n",
    "            finally:\n",
    "                signal.alarm(0)  # Ensure the alarm is always disabled\n",
    "\n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HG-request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "from dotenv import load_dotenv\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "API = os.getenv(\"HF_API\")\n",
    "\n",
    "client = InferenceClient(\n",
    "    token=API,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timeout_decorator(time_limit=185) \n",
    "def img_gen(text: str,model:str):\n",
    "    start=time.time()\n",
    "    \n",
    "    client = InferenceClient(model=model,token=API)\n",
    "    \n",
    "    try:\n",
    "        image = client.text_to_image(f\"Text:{text}\")\n",
    "    except Exception as e:\n",
    "        return 18,f\"Error:{e}\"\n",
    "    \n",
    "    end=time.time()\n",
    "    name=model.replace(\"/\",\"_\")\n",
    "    image.save(f'''./Images/{name}.png''')\n",
    "    image.save(f'''/home/prince/Obsidian/BOOK_VIZ/Images/{name}.png''')\n",
    "    \n",
    "    time_taken_img=end-start\n",
    "    if time_taken_img>60:\n",
    "        time_taken_img=time_taken_img/60\n",
    "        return time_taken_img,f\"{time_taken_img} mins\"\n",
    "    else:\n",
    "        return time_taken_img,f\"{end-start} sec\"\n",
    "\n",
    "\n",
    "def get_path(name):\n",
    "    name=name.replace(\"/\",\"_\")\n",
    "    return f'''![img](Images/{name}.png)'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "models=[\n",
    "    \"strangerzonehf/Qs-Sketch\",\n",
    "    \"black-forest-labs/flux.1-dev\",\n",
    "    \"black-forest-labs/FLUX.1-schnell\",\n",
    "    \"CompVis/stable-diffusion-v1-4\",\n",
    "    \"digiplay/aurorafantasy_v1\",\n",
    "    \"digiplay/Blazarot_blazaroshi\",\n",
    "    \"digiplay/darkphoenix3D_v1.1\",\n",
    "    \"digiplay/darkphoenix3D_v1.1\",\n",
    "    \"digiplay/PerfectDeliberate-Anime_v2\",\n",
    "    \"digiplay/Photon_v1\",\n",
    "    \"digiplay/rRealism_v1.0_riiwa\",\n",
    "    \"digiplay/ya3_xt\",\n",
    "    \"enhanceaiteam/FLUX.1-Pro\",\n",
    "    \"fluently/Fluently-XL-v4\",\n",
    "    \"John6666/asyncs-mix-pony-pony-v1-sdxl\",\n",
    "    \"John6666/cyberrealistic-pony-v63-sdxl\",\n",
    "    \"Lykon/AAM_XL_AnimeMix\",\n",
    "    \"Niggendar/duchaitenPonyXLNo_v35\",\n",
    "    \"playgroundai/playground-v2-1024px-aesthetic\",\n",
    "    \"sayakpaul/FLUX.1-dev-edit-v0\",\n",
    "    \"stabilityai/stable-diffusion-2\",\n",
    "    \"stabilityai/stable-diffusion-3-medium-diffusers\",\n",
    "    \"stabilityai/stable-diffusion-3.5-large\",\n",
    "    \"stabilityai/stable-diffusion-3.5-large-turbo\",\n",
    "    \"stabilityai/stable-diffusion-xl-base-1.0\",\n",
    "    \"stable-diffusion-v1-5/stable-diffusion-v1-5\",\n",
    "    \"Yntec/epiCPhotoGasm\",\n",
    "    \"Yntec/ICantBelieveItSNotPhotography\",\n",
    "    \"Yntec/IncredibleLife\",\n",
    "    \"Yntec/IncredibleWorld\",\n",
    "    \"Yntec/IncredibleWorld2\",\n",
    "    \"Yntec/TrueSight\"\n",
    "]\n",
    "\n",
    "model_links=[\n",
    "    \"![Link](https://huggingface.co/strangerzonehf/Qs-Sketch)\",\n",
    "    \"[Link](https://huggingface.co/black-forest-labs/FLUX.1-dev)\",\n",
    "    \"[Link](https://huggingface.co/black-forest-labs/FLUX.1-schnell)\",\n",
    "    \"[Link](https://huggingface.co/CompVis/stable-diffusion-v1-4)\",\n",
    "    \"[Link](https://huggingface.co/digiplay/aurorafantasy_v1)\",\n",
    "    \"[Link](https://huggingface.co/digiplay/Blazarot_blazaroshi)\",\n",
    "    \"[Link](https://huggingface.co/digiplay/darkphoenix3D_v1.1)\",\n",
    "    \"[Link](https://huggingface.co/digiplay/darkphoenix3D_v1.1)\",\n",
    "    \"[Link](https://huggingface.co/digiplay/PerfectDeliberate-Anime_v2)\",\n",
    "    \"[Link](https://huggingface.co/digiplay/Photon_v1)\",\n",
    "    \"[Link](https://huggingface.co/digiplay/rRealism_v1.0_riiwa)\",\n",
    "    \"[Link](https://huggingface.co/digiplay/ya3_xt)\",\n",
    "    \"[Link](https://huggingface.co/enhanceaiteam/FLUX.1-Pro)\",\n",
    "    \"[Link](https://huggingface.co/fluently/Fluently-XL-v4)\",\n",
    "    \"[Link](https://huggingface.co/John6666/asyncs-mix-pony-pony-v1-sdxl)\",\n",
    "    \"[Link](https://huggingface.co/John6666/cyberrealistic-pony-v63-sdxl)\",\n",
    "    \"[Link](https://huggingface.co/Lykon/AAM_XL_AnimeMix)\",\n",
    "    \"[Link](https://huggingface.co/Niggendar/duchaitenPonyXLNo_v35)\",\n",
    "    \"[Link](https://huggingface.co/playgroundai/playground-v2-1024px-aesthetic)\",\n",
    "    \"[Link](https://huggingface.co/sayakpaul/FLUX.1-dev-edit-v0)\",\n",
    "    \"[Link](https://huggingface.co/stabilityai/stable-diffusion-2)\",\n",
    "    \"[Link](https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers)\",\n",
    "    \"[Link](https://huggingface.co/stabilityai/stable-diffusion-3.5-large)\",\n",
    "    \"[Link](https://huggingface.co/stabilityai/stable-diffusion-3.5-large-turbo)\",\n",
    "    \"[Link](https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0)\",\n",
    "    \"[Link](https://huggingface.co/stable-diffusion-v1-5/stable-diffusion-v1-5)\",\n",
    "    \"[Link](https://huggingface.co/Yntec/epiCPhotoGasm)\",\n",
    "    \"[Link](https://huggingface.co/Yntec/ICantBelieveItSNotPhotography)\",\n",
    "    \"[Link](https://huggingface.co/Yntec/IncredibleLife)\",\n",
    "    \"[Link](https://huggingface.co/Yntec/IncredibleWorld)\",\n",
    "    \"[Link](https://huggingface.co/Yntec/IncredibleWorld2)\",\n",
    "    \"[Link](https://huggingface.co/Yntec/TrueSight)\"\n",
    "]\n",
    "\n",
    "img_path=[get_path(i) for i in models]\n",
    "\n",
    "output_dict={\n",
    "    0:{\n",
    "        \"model_name\": \"\",\n",
    "        \"link\": \"\",\n",
    "        \"time\": \"\",\n",
    "        \"img\": \"\"\n",
    "        },\n",
    "             }\n",
    "\n",
    "for i in range(len(models)):\n",
    "    out={\n",
    "        \"model_name\": \"\",\n",
    "        \"link\": \"\",\n",
    "        \"time\": \"\",\n",
    "        \"img\": \"\"\n",
    "    }\n",
    "    \n",
    "    out[\"model_name\"]=models[i]\n",
    "    out[\"link\"]=model_links[i]\n",
    "    out[\"time\"]=\"\"\n",
    "    out[\"img\"]=img_path[i]\n",
    "    output_dict[i]=out\n",
    "output_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "strangerzonehf/Qs-Sketch is done\n",
      "black-forest-labs/flux.1-dev is done\n",
      "black-forest-labs/FLUX.1-schnell is done\n",
      "CompVis/stable-diffusion-v1-4 is done\n",
      "digiplay/aurorafantasy_v1 is done\n",
      "digiplay/Blazarot_blazaroshi is done\n",
      "digiplay/darkphoenix3D_v1.1 is done\n",
      "digiplay/darkphoenix3D_v1.1 is done\n",
      "digiplay/PerfectDeliberate-Anime_v2 is done\n",
      "digiplay/Photon_v1 is done\n",
      "digiplay/rRealism_v1.0_riiwa is done\n",
      "digiplay/ya3_xt is done\n",
      "enhanceaiteam/FLUX.1-Pro is done\n",
      "fluently/Fluently-XL-v4 is done\n",
      "John6666/asyncs-mix-pony-pony-v1-sdxl is done\n",
      "John6666/cyberrealistic-pony-v63-sdxl is done\n",
      "Lykon/AAM_XL_AnimeMix is done\n",
      "Niggendar/duchaitenPonyXLNo_v35 is done\n",
      "playgroundai/playground-v2-1024px-aesthetic is done\n",
      "sayakpaul/FLUX.1-dev-edit-v0 is done\n",
      "stabilityai/stable-diffusion-2 is done\n",
      "stabilityai/stable-diffusion-3-medium-diffusers is done\n",
      "stabilityai/stable-diffusion-3.5-large is done\n",
      "stabilityai/stable-diffusion-3.5-large-turbo is done\n",
      "stabilityai/stable-diffusion-xl-base-1.0 is done\n",
      "stable-diffusion-v1-5/stable-diffusion-v1-5 is done\n",
      "Yntec/epiCPhotoGasm is done\n",
      "Yntec/ICantBelieveItSNotPhotography is done\n",
      "Yntec/IncredibleLife is done\n",
      "Yntec/IncredibleWorld is done\n",
      "Yntec/IncredibleWorld2 is done\n",
      "Yntec/TrueSight is done\n"
     ]
    }
   ],
   "source": [
    "times=[]\n",
    "text=\"A rocky surface under a starry night sky. A small boy with golden hair sits holding a box, gazing at it thoughtfully. A pilot stands nearby, observing the boy. Distant planets glow faintly in the background.//Style - landscape \"\n",
    "text1= \"A vast, starry expanse with a tiny planet barely visible in the distance. The planet is small, no larger than a house, with a single glowing light on its surface. The narrator stands in the foreground, looking toward the planet with a mix of awe and curiosity.\"\n",
    "for idx,model in enumerate(models):\n",
    "    \n",
    "    int_time,time_taken=img_gen(text,model)\n",
    "    \n",
    "    times.append((model,time_taken))\n",
    "    \n",
    "    output_dict[idx][\"time\"]=time_taken\n",
    "    \n",
    "    if int_time<18:\n",
    "        time.sleep(18-int_time)\n",
    "    \n",
    "    print(f\"{model} is done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "# Save the dictionary as a JSON file\n",
    "with open(\"./Model_lists/data.json\", \"w\") as json_file:\n",
    "    json.dump(output_dict, json_file, indent=4)  # `indent=4` makes it pretty-printed\n",
    "\n",
    "print(\"Data has been saved to 'data.json'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Filetering // Error handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty=[]\n",
    "for i in output_dict.values():\n",
    "    if i[\"time\"] == \"NA\":\n",
    "        empty.append(i[\"model_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['black-forest-labs/flux.1-dev', 'digiplay/Photon_v1']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty=[\n",
    "    \"black-forest-labs/flux.1-dev\",\n",
    "    \"digiplay/Photon_v1\"\n",
    "    ]\n",
    "empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "black-forest-labs/flux.1-dev is done\n",
      "digiplay/Photon_v1 is done\n"
     ]
    }
   ],
   "source": [
    "times=[]\n",
    "text=\"A rocky surface under a starry night sky. A small boy with golden hair sits holding a box, gazing at it thoughtfully. A pilot stands nearby, observing the boy. Distant planets glow faintly in the background.//Style - landscape \"\n",
    "text1= \"A vast, starry expanse with a tiny planet barely visible in the distance. The planet is small, no larger than a house, with a single glowing light on its surface. The narrator stands in the foreground, looking toward the planet with a mix of awe and curiosity.\"\n",
    "\n",
    "for idx,model in enumerate(empty):\n",
    "        \n",
    "    int_time,time_taken=img_gen(text1,model)\n",
    "    \n",
    "    times.append((model,time_taken))\n",
    "    if int_time<18:\n",
    "        time.sleep(18-int_time)\n",
    "    print(f\"{model} is done\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "___\n",
    "___\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEXT_TO_TEXT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing the api call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "import requests\n",
    "import time\n",
    "from reader import read_json\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from pydantic import BaseModel,ValidationError,confloat\n",
    "import json\n",
    "\n",
    "from huggingface_hub import InferenceClient\n",
    "import time\n",
    "\n",
    "client = InferenceClient(\n",
    "    token=API,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'properties': {'scenes': {'additionalProperties': {'type': 'string'}, 'title': 'Scenes', 'type': 'object'}}, 'required': ['scenes'], 'title': 'SceneSchema', 'type': 'object'}\n"
     ]
    }
   ],
   "source": [
    "class SceneSchema(BaseModel):\n",
    "    scenes: Dict[str,str]\n",
    "print(SceneSchema.model_json_schema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "role='''\n",
    "**Role**: Scene-to-Prompt Generator  \n",
    "**Task**: Split a book chapter into scenes (location/time/character changes) and create text-to-image prompts.  \n",
    "\n",
    "**Inputs**\n",
    "Text:A chapter from a book\n",
    "\n",
    "**Output Format**:  \n",
    "\n",
    "{  \n",
    "  \"scenes\": {  \n",
    "    \"Scene [N]\": \"Detailed prompt including location, time, character appearances, and atmosphere.\"  \n",
    "  }  \n",
    "}  \n",
    "\n",
    "**Example**:  \n",
    "- **Input**: \"Emma entered the dark forest at sunset. Later, she met an old woman in a cottage.\"  \n",
    "- **Output**:  \n",
    "{  \n",
    "  \"scenes\": {  \n",
    "    \"Scene 1\": \"Young woman (Emma, red hooded cloak, basket) in a dark forest at sunset. Tall trees, long shadows, tense mood.\",  \n",
    "    \"Scene 2\": \"Dim cottage at night. Old woman (silver hair, rocking chair) by a fire. Warm, cozy atmosphere.\"  \n",
    "  }  \n",
    "}  \n",
    "\n",
    "**Rules**:  \n",
    "1. Use concise prompts.  \n",
    "2. Follow JSON schema strictly.  \n",
    "3. Prioritize explicit details (appearance, location, time).\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "API = os.getenv(\"HF_API\")\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {API}\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "}\n",
    "def llm_req(url, text: str,model_type:str) -> str:\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": f\"{role}\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": text\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # # Prepare the data payload\n",
    "    # data_instruct = { # Add the \"inputs\" field\n",
    "    #         \"messages\": messages,\n",
    "    #         \"temperature\": 0,  # Control the randomness of the response\n",
    "    #         \"stream\": False,\n",
    "    #         \"repetition_penalty\": 1.3,\n",
    "    #         \"grammar\": {\n",
    "    #             \"type\": \"json\",\n",
    "    #             \"value\": SceneSchema.model_json_schema()\n",
    "    #         }\n",
    "    #     }\n",
    "    \n",
    "    data_instruct = {\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": 0.7,\n",
    "        \"stream\": False,\n",
    "        \"max_tokens\":10000,\n",
    "        \"parameters\": {\n",
    "            \"repetition_penalty\": 1.3,\n",
    "            \"grammar\": {\n",
    "            \"type\": \"json\",\n",
    "            \"value\": SceneSchema.model_json_schema()\n",
    "                }\n",
    "                    }\n",
    "    }\n",
    "    \n",
    "    data_base={\n",
    "    \"inputs\": f\"# Ruls\\n {role}\\n\\n # input->\\n{text}\",\n",
    "    \"parameters\": {\n",
    "        \"max_new_tokens\": 50,  # Max response length\n",
    "        \"temperature\": 0.7,    # Creativity control\n",
    "        \"return_full_text\": False,\n",
    "        \"repetition_penalty\": 1.3,\n",
    "        \"grammar\": {\n",
    "                \"type\": \"json\",\n",
    "                \"value\": SceneSchema.model_json_schema()\n",
    "            }\n",
    "    }\n",
    "}\n",
    "    if model_type.lower()==\"instruct\":\n",
    "        data=data_instruct\n",
    "    else:\n",
    "        data=data_base\n",
    "    print(data)\n",
    "    try:\n",
    "        # Make the API request\n",
    "        response = requests.post(url=url, headers=headers, json=data, timeout=60)\n",
    "\n",
    "        print(response.json())\n",
    "        # Check the response status code\n",
    "        if response.status_code == 200:\n",
    "            response_data = response.json()\n",
    "            # Extract the assistant's message content\n",
    "            assistant_message = response_data[\"choices\"][0][\"message\"][\"content\"]\n",
    "            return False, assistant_message\n",
    "        else:\n",
    "            print(f\"Error: {response.status_code}, {response.text}\")  # Print error details\n",
    "            # if response.status_code==422 and  response.text==\"Failed to deserialize the JSON body into the target type: inputs: invalid type: map, expected a string at line 1 column 11\":\n",
    "                \n",
    "            return True, f\"Error: {response.status_code}, {response.text}\"\n",
    "    except Exception as e:\n",
    "        print(f\"Request Failed: {str(e)}\")\n",
    "        return True, f\"Request Failed: {str(e)}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### List of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client.list_deployed_models()['text-generation']\n",
    "\n",
    "\n",
    "model_urls = {\n",
    "    \"01-ai/Yi-1.5-34B-Chat\": {\n",
    "        \"url\": \"https://api-inference.huggingface.co/models/01-ai/Yi-1.5-34B-Chat\",\n",
    "        \"type\": \"instruct\"  # \"Chat\" indicates instruction tuning :cite[2]:cite[8]\n",
    "    },\n",
    "    \"AdityaLavaniya/TinyLlama-Fitness-Instructor\": {\n",
    "        \"url\": \"https://api-inference.huggingface.co/models/AdityaLavaniya/TinyLlama-Fitness-Instructor\",\n",
    "        \"type\": \"instruct\"  # \"Instructor\" implies instruction tuning\n",
    "    },\n",
    "    \"ai-forever/rugpt3small_based_on_gpt2\": {\n",
    "        \"url\": \"https://api-inference.huggingface.co/models/ai-forever/rugpt3small_based_on_gpt2\",\n",
    "        \"type\": \"base\"  # Base GPT-2 variant :cite[2]\n",
    "    },\n",
    "    \"bigcode/octocoder\": {\n",
    "        \"url\": \"https://api-inference.huggingface.co/models/bigcode/octocoder\",\n",
    "        \"type\": \"instruct\"  # Code-specific instruction tuning\n",
    "    },\n",
    "    \"bigcode/santacoder\": {\n",
    "        \"url\": \"https://api-inference.huggingface.co/models/bigcode/santacoder\",\n",
    "        \"type\": \"base\"  # No explicit instruction tuning in name\n",
    "    },\n",
    "    \"bigcode/starcoder\": {\n",
    "        \"url\": \"https://api-inference.huggingface.co/models/bigcode/starcoder\",\n",
    "        \"type\": \"base\"\n",
    "    },\n",
    "    \"bigcode/starcoder2-15b\": {\n",
    "        \"url\": \"https://api-inference.huggingface.co/models/bigcode/starcoder2-15b\",\n",
    "        \"type\": \"base\"\n",
    "    },\n",
    "    \"bigcode/starcoder2-3b\": {\n",
    "        \"url\": \"https://api-inference.huggingface.co/models/bigcode/starcoder2-3b\",\n",
    "        \"type\": \"base\"\n",
    "    },\n",
    "    \"bigcode/starcoderplus\": {\n",
    "        \"url\": \"https://api-inference.huggingface.co/models/bigcode/starcoderplus\",\n",
    "        \"type\": \"base\"\n",
    "    },\n",
    "    \"codellama/CodeLlama-13b-hf\": {\n",
    "        \"url\": \"https://api-inference.huggingface.co/models/codellama/CodeLlama-13b-hf\",\n",
    "        \"type\": \"base\"  # Code-focused base model :cite[10]\n",
    "    },\n",
    "    \"codellama/CodeLlama-34b-Instruct-hf\": {\n",
    "        \"url\": \"https://api-inference.huggingface.co/models/codellama/CodeLlama-34b-Instruct-hf\",\n",
    "        \"type\": \"instruct\"  # \"Instruct\" in name :cite[5]\n",
    "    },\n",
    "    \"codellama/CodeLlama-7b-hf\": {\n",
    "        \"url\": \"https://api-inference.huggingface.co/models/codellama/CodeLlama-7b-hf\",\n",
    "        \"type\": \"base\"\n",
    "    },\n",
    "    \"CohereForAI/aya-23-35B\": {\n",
    "        \"url\": \"https://api-inference.huggingface.co/models/CohereForAI/aya-23-35B\",\n",
    "        \"type\": \"base\"  # Multilingual base model :cite[1]\n",
    "    },\n",
    "    \"CohereForAI/c4ai-command-r-plus-08-2024\": {\n",
    "        \"url\": \"https://api-inference.huggingface.co/models/CohereForAI/c4ai-command-r-plus-08-2024\",\n",
    "        \"type\": \"instruct\"  # \"Command\" implies instruction tuning :cite[1]\n",
    "    },\n",
    "    \"deepseek-ai/DeepSeek-Coder-V2-Instruct\": {\n",
    "        \"url\": \"https://api-inference.huggingface.co/models/deepseek-ai/DeepSeek-Coder-V2-Instruct\",\n",
    "        \"type\": \"instruct\"  # Explicit \"Instruct\" tag :cite[1]\n",
    "    },\n",
    "    \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\": {\n",
    "        \"url\": \"https://api-inference.huggingface.co/models/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\n",
    "        \"type\": \"base\"  # No instruction indicators\n",
    "    },\n",
    "    \"deepseek-ai/DeepSeek-R1-Distill-Qwen-32B\": {\n",
    "        \"url\": \"https://api-inference.huggingface.co/models/deepseek-ai/DeepSeek-R1-Distill-Qwen-32B\",\n",
    "        \"type\": \"base\"\n",
    "    },\n",
    "    \"distilbert/distilgpt2\": {\n",
    "        \"url\": \"https://api-inference.huggingface.co/models/distilbert/distilgpt2\",\n",
    "        \"type\": \"base\"  # Distilled base model :cite[2]\n",
    "    },\n",
    "    \"EleutherAI/gpt-neo-1.3B\": {\n",
    "        \"url\": \"https://api-inference.huggingface.co/models/EleutherAI/gpt-neo-1.3B\",\n",
    "        \"type\": \"base\"\n",
    "    },\n",
    "    \"EleutherAI/gpt-neo-2.7B\": {\n",
    "        \"url\": \"https://api-inference.huggingface.co/models/EleutherAI/gpt-neo-2.7B\",\n",
    "        \"type\": \"base\"\n",
    "    },\n",
    "    \"EleutherAI/gpt-neox-20b\": {\n",
    "        \"url\": \"https://api-inference.huggingface.co/models/EleutherAI/gpt-neox-20b\",\n",
    "        \"type\": \"base\"\n",
    "    },\n",
    "    \"google/gemma-1.1-2b-it\": {\n",
    "        \"url\": \"https://api-inference.huggingface.co/models/google/gemma-1.1-2b-it\",\n",
    "        \"type\": \"instruct\"  # \"-it\" suffix denotes instruction tuning :cite[2]\n",
    "    },\n",
    "    \"google/gemma-1.1-7b-it\": {\n",
    "        \"url\": \"https://api-inference.huggingface.co/models/google/gemma-1.1-7b-it\",\n",
    "        \"type\": \"instruct\"\n",
    "    },\n",
    "    \"google/gemma-2-27b-it\": {\n",
    "        \"url\": \"https://api-inference.huggingface.co/models/google/gemma-2-27b-it\",\n",
    "        \"type\": \"instruct\"\n",
    "    },\n",
    "    \"google/gemma-2-2b-it\": {\n",
    "        \"url\": \"https://api-inference.huggingface.co/models/google/gemma-2-2b-it\",\n",
    "        \"type\": \"instruct\"\n",
    "    },\n",
    "    \"google/gemma-2-9b-it\": {\n",
    "        \"url\": \"https://api-inference.huggingface.co/models/google/gemma-2-9b-it\",\n",
    "        \"type\": \"instruct\"\n",
    "    },\n",
    "    \"google/gemma-2b\": {\n",
    "        \"url\": \"https://api-inference.huggingface.co/models/google/gemma-2b\",\n",
    "        \"type\": \"base\"\n",
    "    },\n",
    "    \"google/gemma-7b\": {\n",
    "        \"url\": \"https://api-inference.huggingface.co/models/google/gemma-7b\",\n",
    "        \"type\": \"base\"\n",
    "    },\n",
    "    \"Gustavosta/MagicPrompt-Stable-Diffusion\": {\n",
    "        \"url\": \"https://api-inference.huggingface.co/models/Gustavosta/MagicPrompt-Stable-Diffusion\",\n",
    "        \"type\": \"instruct\"  # Designed for instruction-like prompt generation :cite[1]\n",
    "    },\n",
    "    \"HuggingFaceH4/starchat-beta\": {\n",
    "        \"url\": \"https://api-inference.huggingface.co/models/HuggingFaceH4/starchat-beta\",\n",
    "        \"type\": \"instruct\"  # \"chat\" in name :cite[2]\n",
    "    },\n",
    "    \"HuggingFaceH4/starchat2-15b-v0.1\": {\n",
    "        \"url\": \"https://api-inference.huggingface.co/models/HuggingFaceH4/starchat2-15b-v0.1\",\n",
    "        \"type\": \"instruct\"\n",
    "    },\n",
    "    \"HuggingFaceH4/zephyr-7b-alpha\": {\n",
    "        \"url\": \"https://api-inference.huggingface.co/models/HuggingFaceH4/zephyr-7b-alpha\",\n",
    "        \"type\": \"instruct\"  # Zephyr models are instruction-tuned :cite[1]\n",
    "    },\n",
    "    \"HuggingFaceH4/zephyr-7b-beta\": {\n",
    "        \"url\": \"https://api-inference.huggingface.co/models/HuggingFaceH4/zephyr-7b-beta\",\n",
    "        \"type\": \"instruct\"\n",
    "    },\n",
    "    \"HuggingFaceM4/idefics-9b-instruct\": {\n",
    "        \"url\": \"https://api-inference.huggingface.co/models/HuggingFaceM4/idefics-9b-instruct\",\n",
    "        \"type\": \"instruct\"  # \"instruct\" in name :cite[4]\n",
    "    },\n",
    "    \"HuggingFaceM4/idefics2-8b\": {\n",
    "        \"url\": \"https://api-inference.huggingface.co/models/HuggingFaceM4/idefics2-8b\",\n",
    "        \"type\": \"base\"  # Base multimodal model :cite[4]\n",
    "    },\n",
    "    \"jinaai/reader-lm-1.5b\": {\n",
    "        \"url\": \"https://api-inference.huggingface.co/models/jinaai/reader-lm-1.5b\",\n",
    "        \"type\": \"base\"  # Document understanding base model :cite[4]\n",
    "    },\n",
    "    \"meta-llama/Llama-2-13b-chat-hf\": {\n",
    "        \"url\": \"https://api-inference.huggingface.co/models/meta-llama/Llama-2-13b-chat-hf\",\n",
    "        \"type\": \"instruct\"  # \"chat\" suffix :cite[1]:cite[5]\n",
    "    },\n",
    "    \"meta-llama/Llama-2-70b-chat-hf\": {\n",
    "        \"url\": \"https://api-inference.huggingface.co/models/meta-llama/Llama-2-70b-chat-hf\",\n",
    "        \"type\": \"instruct\"\n",
    "    },\n",
    "    \"meta-llama/Llama-2-7b-chat-hf\": {\n",
    "        \"url\": \"https://api-inference.huggingface.co/models/meta-llama/Llama-2-7b-chat-hf\",\n",
    "        \"type\": \"instruct\"\n",
    "    },\n",
    "    \"meta-llama/Llama-3.1-70B-Instruct\": {\n",
    "        \"url\": \"https://api-inference.huggingface.co/models/meta-llama/Llama-3.1-70B-Instruct\",\n",
    "        \"type\": \"instruct\"  # Explicit \"Instruct\" tag :cite[1]\n",
    "    },\n",
    "    \"meta-llama/Llama-3.1-8B-Instruct\": {\n",
    "        \"url\": \"https://api-inference.huggingface.co/models/meta-llama/Llama-3.1-8B-Instruct\",\n",
    "        \"type\": \"instruct\"\n",
    "    },\n",
    "    \"meta-llama/Llama-Guard-3-8B\": {\n",
    "        \"url\": \"https://api-inference.huggingface.co/models/meta-llama/Llama-Guard-3-8B\",\n",
    "        \"type\": \"instruct\"  # Safety-focused instruction model :cite[1]\n",
    "    },\n",
    "    \"microsoft/Phi-3-mini-128k-instruct\": {\n",
    "        \"url\": \"https://api-inference.huggingface.co/models/microsoft/Phi-3-mini-128k-instruct\",\n",
    "        \"type\": \"instruct\"  # \"instruct\" in name :cite[5]\n",
    "    },\n",
    "    \"microsoft/Phi-3-mini-4k-instruct\": {\n",
    "        \"url\": \"https://api-inference.huggingface.co/models/microsoft/Phi-3-mini-4k-instruct\",\n",
    "        \"type\": \"instruct\"\n",
    "    },\n",
    "    \"mistralai/Mistral-7B-Instruct-v0.1\": {\n",
    "        \"url\": \"https://api-inference.huggingface.co/models/mistralai/Mistral-7B-Instruct-v0.1\",\n",
    "        \"type\": \"instruct\"  # \"Instruct\" in name :cite[2]:cite[8]\n",
    "    },\n",
    "    \"mistralai/Mistral-7B-v0.1\": {\n",
    "        \"url\": \"https://api-inference.huggingface.co/models/mistralai/Mistral-7B-v0.1\",\n",
    "        \"type\": \"base\"  # Base model without tuning :cite[4]\n",
    "    },\n",
    "    \"NousResearch/Hermes-3-Llama-3.1-8B\": {\n",
    "        \"url\": \"https://api-inference.huggingface.co/models/NousResearch/Hermes-3-Llama-3.1-8B\",\n",
    "        \"type\": \"instruct\"  # \"Hermes\" implies instruction tuning :cite[8]\n",
    "    },\n",
    "    \"openai-community/gpt2\": {\n",
    "        \"url\": \"https://api-inference.huggingface.co/models/openai-community/gpt2\",\n",
    "        \"type\": \"base\"  # Original GPT-2 base model :cite[2]\n",
    "    },\n",
    "    \"Qwen/Qwen2.5-72B-Instruct\": {\n",
    "        \"url\": \"https://api-inference.huggingface.co/models/Qwen/Qwen2.5-72B-Instruct\",\n",
    "        \"type\": \"instruct\"  # \"Instruct\" in name :cite[1]\n",
    "    },\n",
    "    \"tiiuae/falcon-7b-instruct\": {\n",
    "        \"url\": \"https://api-inference.huggingface.co/models/tiiuae/falcon-7b-instruct\",\n",
    "        \"type\": \"instruct\"  # Explicit instruction tuning :cite[5]\n",
    "    }, \n",
    "    \"deepseek-ai/DeepSeek-R1-Distill-Qwen-32B\": {\n",
    "        \"url\": \"https://api-inference.huggingface.co/models/deepseek-ai/DeepSeek-R1-Distill-Qwen-32B\",\n",
    "        \"type\": \"instruct\"  # Distilled for reasoning tasks\n",
    "    },\n",
    "    \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\": {\n",
    "        \"url\": \"https://api-inference.huggingface.co/models/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\n",
    "        \"type\": \"instruct\"  # Optimized for instruction following\n",
    "    },\n",
    "    \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\": {\n",
    "        \"url\": \"https://api-inference.huggingface.co/models/deepseek-ai/DeepSeek-R1-Distill-Llama-8B\",\n",
    "        \"type\": \"instruct\"  # Chain-of-thought reasoning focus\n",
    "    },\n",
    "    \"deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\": {\n",
    "        \"url\": \"https://api-inference.huggingface.co/models/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\",\n",
    "        \"type\": \"instruct\"  # High-performance reasoning\n",
    "    },\n",
    "    \"deepseek-ai/DeepSeek-R1-Distill-Qwen-14B\": {\n",
    "        \"url\": \"https://api-inference.huggingface.co/models/deepseek-ai/DeepSeek-R1-Distill-Qwen-14B\",\n",
    "        \"type\": \"instruct\"  # Advanced code generation\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text='''\n",
    "Then she had forced her cough to inflict remorse.\n",
    "Thus the little prince, notwithstanding the goodwill of his love, soon doubted her. He had taken unimportant words seriously and had become very unhappy.\n",
    "\n",
    "\"I should not have listened to him,\" he confided to me one day. \"You must never listen to flowers. You have to look at them and breathe them. Mine embalmed my planet, but I could not rejoice. This story of claws, which had so annoyed me, should have tempted me...\"\n",
    "\n",
    "He again confided to me:\n",
    "\"I did not understand anything! I should have judged her on the acts and not the words. She embarrassed me and enlightened me. I should never have fled! I should have guessed her tenderness behind her poor tricks. The flowers are so contradictory! But I was too young to know how to love her.\"\n",
    "\n",
    "IX\n",
    "I believe that he took advantage of a migration of wild birds for his escape. On the morning of the departure, he put his planet in order. He carefully roamed his active volcanoes. He had two active volcanoes, and it was very convenient to warm up the morning breakfast. He also possessed an extinct volcano. But, as he said, \"You never know!\" He therefore also roamed the extinct volcano. If they are well swept, volcanoes burn gently and regularly, without eruptions. Volcanic eruptions are like chimney fires. Obviously, on our Earth, we are much too small to swallow our volcanoes. That's why they cause us a lot of trouble.\n",
    "\n",
    "The little prince also snatched, with a little melancholy, the last shoots of baobabs. He thought he would never have to come back. But all these familiar labors appeared to him, that morning, extremely sweet. And when he watered the flower for the last time and prepared to shelter it under his globe, he discovered the desire to weep.\n",
    "\n",
    "\"Farewell,\" he said to the flower.\n",
    "But she did not answer.\n",
    "\"Farewell,\" he repeated.\n",
    "\n",
    "The flower coughed. But it was not because of her cold.\n",
    "\"I was a fool,\" she said at last. \"I beg your pardon. Strive to be happy.\"\n",
    "\n",
    "He was surprised by the absence of reproaches. He remained there, disconcerted, the globe in the air. He did not understand this quiet sweetness.\n",
    "\n",
    "\"Yes, I love you,\" said the flower. \"You did not know, by my fault. It has no importance. But you were as stupid as I was. Strive to be happy... Leave this globe quiet. I do not want it anymore.\"\n",
    "\n",
    "\"But the wind...\"\n",
    "\n",
    "\"I'm not so cold as that... The cool air of the night will do me good. I'm a flower.\"\n",
    "\n",
    "\"But the beasts...\"\n",
    "\n",
    "\"I must bear two or three caterpillars if I want to know the butterflies. It seems that it is so beautiful. Otherwise, who will visit me? You will be far away. As for the big beasts, I fear nothing. I have my claws.\"\n",
    "\n",
    "And she naively showed her four thorns. Then she added:\n",
    "\"Do not drag like that, it's annoying. You decided to leave. Go away.\"\n",
    "\n",
    "For she did not want him to see her crying. It was such a proud flower..\n",
    "\n",
    "X\n",
    "He was in the region of the asteroids 325, 326, 327, 328, 329, and 330. He therefore began by visiting them to search for an occupation and to learn.\n",
    "\n",
    "The first was inhabited by a king. The king sat, dressed in purple and ermine, on a very simple and yet majestic throne.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [{'role': 'system', 'content': '\\n**Role**: Scene-to-Prompt Generator  \\n**Task**: Split a book chapter into scenes (location/time/character changes) and create text-to-image prompts.  \\n\\n**Inputs**\\nText:A chapter from a book\\n\\n**Output Format**:  \\n\\n{  \\n  \"scenes\": {  \\n    \"Scene [N]\": \"Detailed prompt including location, time, character appearances, and atmosphere.\"  \\n  }  \\n}  \\n\\n**Example**:  \\n- **Input**: \"Emma entered the dark forest at sunset. Later, she met an old woman in a cottage.\"  \\n- **Output**:  \\n{  \\n  \"scenes\": {  \\n    \"Scene 1\": \"Young woman (Emma, red hooded cloak, basket) in a dark forest at sunset. Tall trees, long shadows, tense mood.\",  \\n    \"Scene 2\": \"Dim cottage at night. Old woman (silver hair, rocking chair) by a fire. Warm, cozy atmosphere.\"  \\n  }  \\n}  \\n\\n**Rules**:  \\n1. Use concise prompts.  \\n2. Follow JSON schema strictly.  \\n3. Prioritize explicit details (appearance, location, time).\\n'}, {'role': 'user', 'content': '\\nThen she had forced her cough to inflict remorse.\\nThus the little prince, notwithstanding the goodwill of his love, soon doubted her. He had taken unimportant words seriously and had become very unhappy.\\n\\n\"I should not have listened to him,\" he confided to me one day. \"You must never listen to flowers. You have to look at them and breathe them. Mine embalmed my planet, but I could not rejoice. This story of claws, which had so annoyed me, should have tempted me...\"\\n\\nHe again confided to me:\\n\"I did not understand anything! I should have judged her on the acts and not the words. She embarrassed me and enlightened me. I should never have fled! I should have guessed her tenderness behind her poor tricks. The flowers are so contradictory! But I was too young to know how to love her.\"\\n\\nIX\\nI believe that he took advantage of a migration of wild birds for his escape. On the morning of the departure, he put his planet in order. He carefully roamed his active volcanoes. He had two active volcanoes, and it was very convenient to warm up the morning breakfast. He also possessed an extinct volcano. But, as he said, \"You never know!\" He therefore also roamed the extinct volcano. If they are well swept, volcanoes burn gently and regularly, without eruptions. Volcanic eruptions are like chimney fires. Obviously, on our Earth, we are much too small to swallow our volcanoes. That\\'s why they cause us a lot of trouble.\\n\\nThe little prince also snatched, with a little melancholy, the last shoots of baobabs. He thought he would never have to come back. But all these familiar labors appeared to him, that morning, extremely sweet. And when he watered the flower for the last time and prepared to shelter it under his globe, he discovered the desire to weep.\\n\\n\"Farewell,\" he said to the flower.\\nBut she did not answer.\\n\"Farewell,\" he repeated.\\n\\nThe flower coughed. But it was not because of her cold.\\n\"I was a fool,\" she said at last. \"I beg your pardon. Strive to be happy.\"\\n\\nHe was surprised by the absence of reproaches. He remained there, disconcerted, the globe in the air. He did not understand this quiet sweetness.\\n\\n\"Yes, I love you,\" said the flower. \"You did not know, by my fault. It has no importance. But you were as stupid as I was. Strive to be happy... Leave this globe quiet. I do not want it anymore.\"\\n\\n\"But the wind...\"\\n\\n\"I\\'m not so cold as that... The cool air of the night will do me good. I\\'m a flower.\"\\n\\n\"But the beasts...\"\\n\\n\"I must bear two or three caterpillars if I want to know the butterflies. It seems that it is so beautiful. Otherwise, who will visit me? You will be far away. As for the big beasts, I fear nothing. I have my claws.\"\\n\\nAnd she naively showed her four thorns. Then she added:\\n\"Do not drag like that, it\\'s annoying. You decided to leave. Go away.\"\\n\\nFor she did not want him to see her crying. It was such a proud flower..\\n\\nX\\nHe was in the region of the asteroids 325, 326, 327, 328, 329, and 330. He therefore began by visiting them to search for an occupation and to learn.\\n\\nThe first was inhabited by a king. The king sat, dressed in purple and ermine, on a very simple and yet majestic throne.\\n'}], 'temperature': 0.7, 'stream': False, 'max_tokens': 10000, 'parameters': {'repetition_penalty': 1.3, 'grammar': {'type': 'json', 'value': {'properties': {'scenes': {'additionalProperties': {'type': 'string'}, 'title': 'Scenes', 'type': 'object'}}, 'required': ['scenes'], 'title': 'SceneSchema', 'type': 'object'}}}}\n",
      "{'object': 'chat.completion', 'id': '', 'created': 1737861104, 'model': 'mistralai/Mistral-7B-Instruct-v0.3', 'system_fingerprint': '3.0.1-sha-bb9095a', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': '{\\n  \"scenes\": {\\n    \"Scene 1\": \"A lonely asteroid with number 325. A king (purple robes, ermine trim) sits on a simple yet majestic throne. Minimalistic background, focus on regal posture.\",\\n    \"Scene 2\": \"Asteroid 326: Empty, empty space. No objects or characters present. Cold, desolate environment.\"\\n  }\\n}'}, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 1144, 'completion_tokens': 100, 'total_tokens': 1244}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "a,b=llm_req(url=\"https://api-inference.huggingface.co/models/mistralai/Mistral-7B-Instruct-v0.3/v1/chat/completions\",text=input_text,model_type=\"instruct\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"scenes\": {\\n    \"Scene 1\": \"A lonely asteroid with number 325. A king (purple robes, ermine trim) sits on a simple yet majestic throne. Minimalistic background, focus on regal posture.\",\\n    \"Scene 2\": \"Asteroid 326: Empty, empty space. No objects or characters present. Cold, desolate environment.\"\\n  }\\n}'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False,\n",
       " {'Scene 1': 'A lonely asteroid with number 325. A king (purple robes, ermine trim) sits on a simple yet majestic throne. Minimalistic background, focus on regal posture.',\n",
       "  'Scene 2': 'Asteroid 326: Empty, empty space. No objects or characters present. Cold, desolate environment.'})"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_json(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_output:Dict[str,dict]={}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'model_json_schema'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[113], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ValidationError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m,e\u001b[38;5;241m.\u001b[39merrors())\n\u001b[0;32m----> 9\u001b[0m validate_json\u001b[38;5;241m.\u001b[39mmodel_json_schema()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'model_json_schema'"
     ]
    }
   ],
   "source": [
    "def validate_json(data: str):\n",
    "    try:\n",
    "        # Parse the JSON using the Pydantic model\n",
    "        data=read_json(data)\n",
    "        validated_data = SceneSchema.model_validate(data)\n",
    "        return (False,validated_data.scenes)\n",
    "    except ValidationError as e:\n",
    "        return (True,e.errors())\n",
    "validate_json.model_json_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutputValidator(BaseModel):\n",
    "    scenes:Dict[str,str]={}\n",
    "    time:float\n",
    "    req_error:bool\n",
    "    json_validation_error:bool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main-Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': '{ \"scenes\": { \"Scene 1 \": \"Little Prince saying goodbye to the rose with sadness while holding watering can with tears in eyes; dimly lit setting sun background near deserted asteroid. Sadness filled air around.\\\\\":{\",'}]\n",
      "Request Failed: list indices must be integers or slices, not str\n"
     ]
    }
   ],
   "source": [
    "a,b=llm_req(url= \"https://api-inference.huggingface.co/models/01-ai/Yi-1.5-34B-Chat\",text=input_text,model_type=\"base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request Failed: [Errno Expecting value] Failed to deserialize the JSON body into the target type: inputs: invalid type: map, expected a string at line 1 column 11: 0\n",
      "01-ai/Yi-1.5-34B-Chat : Model Done.\n",
      "Request Failed: [Errno Expecting value] Failed to deserialize the JSON body into the target type: inputs: invalid type: map, expected a string at line 1 column 11: 0\n",
      "AdityaLavaniya/TinyLlama-Fitness-Instructor : Model Done.\n",
      "[{'generated_text': '{ \"scenes\": { } }'}]\n",
      "Request Failed: list indices must be integers or slices, not str\n",
      "ai-forever/rugpt3small_based_on_gpt2 : Model Done.\n",
      "{'error': 'Service Unavailable'}\n",
      "Error: 503, {\"error\":\"Service Unavailable\"}\n",
      "bigcode/octocoder : Model Done.\n",
      "[{'generated_text': '{\"scenes\":{\"Scene[24]: \" :\"\", \"Scene(2): \\'\\', ...}} = {\" :\"\", \"\" : \"\"} }'}]\n",
      "Request Failed: list indices must be integers or slices, not str\n",
      "bigcode/santacoder : Model Done.\n",
      "[{'generated_text': '{\"scenes\":{}}'}]\n",
      "Request Failed: list indices must be integers or slices, not str\n",
      "bigcode/starcoder : Model Done.\n",
      "[{'generated_text': '{ \"scenes\": { \"Scene 1\": \"King sitting on golden throne looking over vast expanse of desert landscape (purple and orange).\" }}'}]\n",
      "Request Failed: list indices must be integers or slices, not str\n",
      "bigcode/starcoder2-15b : Model Done.\n",
      "[{'generated_text': '{ \"scenes\": { \"A scene\": \"Dude in a white shirt and jeans sitting on a table eating something\" } }'}]\n",
      "Request Failed: list indices must be integers or slices, not str\n",
      "bigcode/starcoder2-3b : Model Done.\n",
      "[{'generated_text': '{\"scenes\":{\\n    }}'}]\n",
      "Request Failed: list indices must be integers or slices, not str\n",
      "bigcode/starcoderplus : Model Done.\n",
      "[{'generated_text': '{ \"scenes\" : {\"the first\": \"a pale, yellowish color; round edges\"} }'}]\n",
      "Request Failed: list indices must be integers or slices, not str\n",
      "codellama/CodeLlama-13b-hf : Model Done.\n",
      "Request Failed: [Errno Expecting value] Failed to deserialize the JSON body into the target type: inputs: invalid type: map, expected a string at line 1 column 11: 0\n",
      "codellama/CodeLlama-34b-Instruct-hf : Model Done.\n",
      "[{'generated_text': '{\"scenes\":{\"Scen[e]\" : \"\"}}'}]\n",
      "Request Failed: list indices must be integers or slices, not str\n",
      "codellama/CodeLlama-7b-hf : Model Done.\n",
      "{'error': 'Model requires a Pro subscription; check out hf.co/pricing to learn more. Make sure to include your HF token in your query.'}\n",
      "Error: 400, {\"error\":\"Model requires a Pro subscription; check out hf.co/pricing to learn more. Make sure to include your HF token in your query.\"}\n",
      "CohereForAI/aya-23-35B : Model Done.\n",
      "{'error': 'Model requires a Pro subscription; check out hf.co/pricing to learn more. Make sure to include your HF token in your query.'}\n",
      "Error: 400, {\"error\":\"Model requires a Pro subscription; check out hf.co/pricing to learn more. Make sure to include your HF token in your query.\"}\n",
      "CohereForAI/c4ai-command-r-plus-08-2024 : Model Done.\n",
      "{'error': 'Model requires a Pro subscription; check out hf.co/pricing to learn more. Make sure to include your HF token in your query.'}\n",
      "Error: 400, {\"error\":\"Model requires a Pro subscription; check out hf.co/pricing to learn more. Make sure to include your HF token in your query.\"}\n",
      "deepseek-ai/DeepSeek-Coder-V2-Instruct : Model Done.\n",
      "Request Failed: [Errno Expecting value] Failed to deserialize the JSON body into the target type: inputs: invalid type: map, expected a string at line 1 column 11: 0\n",
      "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B : Model Done.\n",
      "Request Failed: [Errno Expecting value] Failed to deserialize the JSON body into the target type: inputs: invalid type: map, expected a string at line 1 column 11: 0\n",
      "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B : Model Done.\n",
      "{'error': 'Input validation error: `inputs` tokens + `max_new_tokens` must be <= 1024. Given: 1097 `inputs` tokens and 50 `max_new_tokens`', 'error_type': 'validation'}\n",
      "Error: 422, {\"error\":\"Input validation error: `inputs` tokens + `max_new_tokens` must be <= 1024. Given: 1097 `inputs` tokens and 50 `max_new_tokens`\",\"error_type\":\"validation\"}\n",
      "distilbert/distilgpt2 : Model Done.\n",
      "[{'generated_text': '{\"scenes\": {\"Mott\": \"Blue\", \"Servant\": \"Silver Hair, Rocker\", \"Eyes\": \"Brown Eyes\", \"Hair\": \"Brown\", \"Voice\": \"Low\", \"Head\": \"Round'}]\n",
      "Request Failed: list indices must be integers or slices, not str\n",
      "EleutherAI/gpt-neo-1.3B : Model Done.\n",
      "[{'generated_text': '{\"scenes\": {\"Age\": \"17\",\"Time\": \"midnight\",\"Character\": \"King\"} }'}]\n",
      "Request Failed: list indices must be integers or slices, not str\n",
      "EleutherAI/gpt-neo-2.7B : Model Done.\n",
      "[{'generated_text': '{\"scenes\":{\"Asteroid325\":\"Kingdom\",\"Said King:\" : \"\"}}'}]\n",
      "Request Failed: list indices must be integers or slices, not str\n",
      "EleutherAI/gpt-neox-20b : Model Done.\n",
      "Request Failed: [Errno Expecting value] Failed to deserialize the JSON body into the target type: inputs: invalid type: map, expected a string at line 1 column 11: 0\n",
      "google/gemma-1.1-2b-it : Model Done.\n",
      "Request Failed: [Errno Expecting value] Failed to deserialize the JSON body into the target type: inputs: invalid type: map, expected a string at line 1 column 11: 0\n",
      "google/gemma-1.1-7b-it : Model Done.\n",
      "Request Failed: [Errno Expecting value] Failed to deserialize the JSON body into the target type: inputs: invalid type: map, expected a string at line 1 column 11: 0\n",
      "google/gemma-2-27b-it : Model Done.\n",
      "Request Failed: [Errno Expecting value] Failed to deserialize the JSON body into the target type: inputs: invalid type: map, expected a string at line 1 column 11: 0\n",
      "google/gemma-2-2b-it : Model Done.\n",
      "Request Failed: [Errno Expecting value] Failed to deserialize the JSON body into the target type: inputs: invalid type: map, expected a string at line 1 column 11: 0\n",
      "google/gemma-2-9b-it : Model Done.\n",
      "[{'generated_text': '{\"scenes\":{}}'}]\n",
      "Request Failed: list indices must be integers or slices, not str\n",
      "google/gemma-2b : Model Done.\n",
      "[{'generated_text': '{\"scenes\":{\"prompt\":\"King sits lonely atop rocky ledge overlooking ocean\",\"width Leurs de la mer<h3>S</h3><h2>a</h2>L<h1>e</h1>R<A>T</d4cK><fF}{J&P;qO'}]\n",
      "Request Failed: list indices must be integers or slices, not str\n",
      "google/gemma-7b : Model Done.\n",
      "{'error': 'Model Gustavosta/MagicPrompt-Stable-Diffusion is currently loading', 'estimated_time': 20.413684844970703}\n",
      "Error: 503, {\"error\":\"Model Gustavosta/MagicPrompt-Stable-Diffusion is currently loading\",\"estimated_time\":20.413684844970703}\n",
      "Gustavosta/MagicPrompt-Stable-Diffusion : Model Done.\n",
      "Request Failed: [Errno Expecting value] Failed to deserialize the JSON body into the target type: inputs: invalid type: map, expected a string at line 1 column 11: 0\n",
      "HuggingFaceH4/starchat-beta : Model Done.\n",
      "Request Failed: [Errno Expecting value] Failed to deserialize the JSON body into the target type: inputs: invalid type: map, expected a string at line 1 column 11: 0\n",
      "HuggingFaceH4/starchat2-15b-v0.1 : Model Done.\n",
      "Request Failed: [Errno Expecting value] Failed to deserialize the JSON body into the target type: inputs: invalid type: map, expected a string at line 1 column 11: 0\n",
      "HuggingFaceH4/zephyr-7b-alpha : Model Done.\n",
      "Request Failed: [Errno Expecting value] Failed to deserialize the JSON body into the target type: inputs: invalid type: map, expected a string at line 1 column 11: 0\n",
      "HuggingFaceH4/zephyr-7b-beta : Model Done.\n",
      "Request Failed: [Errno Expecting value] Failed to deserialize the JSON body into the target type: inputs: invalid type: map, expected a string at line 1 column 11: 0\n",
      "HuggingFaceM4/idefics-9b-instruct : Model Done.\n",
      "{'error': 'image-text-to-text is not a valid pipeline'}\n",
      "Error: 500, {\"error\":\"image-text-to-text is not a valid pipeline\"}\n",
      "HuggingFaceM4/idefics2-8b : Model Done.\n",
      "{'error': 'Model jinaai/reader-lm-1.5b is currently loading', 'estimated_time': 123.49713897705078}\n",
      "Error: 503, {\"error\":\"Model jinaai/reader-lm-1.5b is currently loading\",\"estimated_time\":123.49713897705078}\n",
      "jinaai/reader-lm-1.5b : Model Done.\n",
      "{'error': 'Model requires a Pro subscription; check out hf.co/pricing to learn more. Make sure to include your HF token in your query.'}\n",
      "Error: 400, {\"error\":\"Model requires a Pro subscription; check out hf.co/pricing to learn more. Make sure to include your HF token in your query.\"}\n",
      "meta-llama/Llama-2-13b-chat-hf : Model Done.\n",
      "{'error': 'Model requires a Pro subscription; check out hf.co/pricing to learn more. Make sure to include your HF token in your query.'}\n",
      "Error: 400, {\"error\":\"Model requires a Pro subscription; check out hf.co/pricing to learn more. Make sure to include your HF token in your query.\"}\n",
      "meta-llama/Llama-2-70b-chat-hf : Model Done.\n",
      "{'error': 'Model requires a Pro subscription; check out hf.co/pricing to learn more. Make sure to include your HF token in your query.'}\n",
      "Error: 400, {\"error\":\"Model requires a Pro subscription; check out hf.co/pricing to learn more. Make sure to include your HF token in your query.\"}\n",
      "meta-llama/Llama-2-7b-chat-hf : Model Done.\n",
      "{'error': 'Model requires a Pro subscription; check out hf.co/pricing to learn more. Make sure to include your HF token in your query.'}\n",
      "Error: 400, {\"error\":\"Model requires a Pro subscription; check out hf.co/pricing to learn more. Make sure to include your HF token in your query.\"}\n",
      "meta-llama/Llama-3.1-70B-Instruct : Model Done.\n",
      "{'error': 'Model requires a Pro subscription; check out hf.co/pricing to learn more. Make sure to include your HF token in your query.'}\n",
      "Error: 400, {\"error\":\"Model requires a Pro subscription; check out hf.co/pricing to learn more. Make sure to include your HF token in your query.\"}\n",
      "meta-llama/Llama-3.1-8B-Instruct : Model Done.\n",
      "{'error': 'Model requires a Pro subscription; check out hf.co/pricing to learn more. Make sure to include your HF token in your query.'}\n",
      "Error: 400, {\"error\":\"Model requires a Pro subscription; check out hf.co/pricing to learn more. Make sure to include your HF token in your query.\"}\n",
      "meta-llama/Llama-Guard-3-8B : Model Done.\n",
      "{'error': 'Model microsoft/Phi-3-mini-128k-instruct is currently loading', 'estimated_time': 305.6863708496094}\n",
      "Error: 503, {\"error\":\"Model microsoft/Phi-3-mini-128k-instruct is currently loading\",\"estimated_time\":305.6863708496094}\n",
      "microsoft/Phi-3-mini-128k-instruct : Model Done.\n",
      "Request Failed: [Errno Expecting value] Failed to deserialize the JSON body into the target type: inputs: invalid type: map, expected a string at line 1 column 11: 0\n",
      "microsoft/Phi-3-mini-4k-instruct : Model Done.\n",
      "{'error': 'Service Unavailable'}\n",
      "Error: 503, {\"error\":\"Service Unavailable\"}\n",
      "mistralai/Mistral-7B-Instruct-v0.1 : Model Done.\n",
      "{'error': 'Service Unavailable'}\n",
      "Error: 503, {\"error\":\"Service Unavailable\"}\n",
      "mistralai/Mistral-7B-v0.1 : Model Done.\n",
      "Request Failed: [Errno Expecting value] Failed to deserialize the JSON body into the target type: inputs: invalid type: map, expected a string at line 1 column 11: 0\n",
      "NousResearch/Hermes-3-Llama-3.1-8B : Model Done.\n",
      "{'error': 'Input validation error: `inputs` tokens + `max_new_tokens` must be <= 1024. Given: 1097 `inputs` tokens and 50 `max_new_tokens`', 'error_type': 'validation'}\n",
      "Error: 422, {\"error\":\"Input validation error: `inputs` tokens + `max_new_tokens` must be <= 1024. Given: 1097 `inputs` tokens and 50 `max_new_tokens`\",\"error_type\":\"validation\"}\n",
      "openai-community/gpt2 : Model Done.\n",
      "Request Failed: [Errno Expecting value] Failed to deserialize the JSON body into the target type: inputs: invalid type: map, expected a string at line 1 column 11: 0\n",
      "Qwen/Qwen2.5-72B-Instruct : Model Done.\n",
      "Request Failed: [Errno Expecting value] Failed to deserialize the JSON body into the target type: inputs: invalid type: map, expected a string at line 1 column 11: 0\n",
      "tiiuae/falcon-7b-instruct : Model Done.\n",
      "{'error': 'The model deepseek-ai/DeepSeek-R1-Distill-Llama-8B is too large to be loaded automatically (16GB > 10GB).'}\n",
      "Error: 403, {\"error\":\"The model deepseek-ai/DeepSeek-R1-Distill-Llama-8B is too large to be loaded automatically (16GB > 10GB).\"}\n",
      "deepseek-ai/DeepSeek-R1-Distill-Llama-8B : Model Done.\n",
      "{'error': 'The model deepseek-ai/DeepSeek-R1-Distill-Qwen-7B is too large to be loaded automatically (15GB > 10GB).'}\n",
      "Error: 403, {\"error\":\"The model deepseek-ai/DeepSeek-R1-Distill-Qwen-7B is too large to be loaded automatically (15GB > 10GB).\"}\n",
      "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B : Model Done.\n",
      "{'error': 'The model deepseek-ai/DeepSeek-R1-Distill-Qwen-14B is too large to be loaded automatically (29GB > 10GB).'}\n",
      "Error: 403, {\"error\":\"The model deepseek-ai/DeepSeek-R1-Distill-Qwen-14B is too large to be loaded automatically (29GB > 10GB).\"}\n",
      "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B : Model Done.\n"
     ]
    }
   ],
   "source": [
    "for name,details in model_urls.items():\n",
    "    url=details[\"url\"]\n",
    "    model_type=details[\"type\"]\n",
    "    \n",
    "    start=time.time()\n",
    "    req_error,output_text=llm_req(url=url,text=input_text,model_type=model_type)\n",
    "    end=time.time()\n",
    "    \n",
    "    scene_dict = {}\n",
    "    validation_error=False\n",
    "    \n",
    "    if not req_error:\n",
    "        validation_error,raw_scene=validate_json(output_text)    \n",
    "        if not validation_error:\n",
    "            scene_dict=raw_scene   \n",
    "                \n",
    "    output_json=OutputValidator(\n",
    "        scenes=scene_dict,\n",
    "        time=round(end-start,2),\n",
    "        req_error=req_error,\n",
    "        json_validation_error=validation_error,\n",
    "        ).model_dump_json(indent=2)\n",
    "            \n",
    "    llm_output[name]=output_json\n",
    "    print(f\"{name} : Model Done.\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'01-ai/Yi-1.5-34B-Chat': '{\\n  \"scenes\": {},\\n  \"time\": 1.57,\\n  \"req_error\": true,\\n  \"json_validation_error\": false\\n}',\n",
       " 'AdityaLavaniya/TinyLlama-Fitness-Instructor': '{\\n  \"scenes\": {},\\n  \"time\": 1.62,\\n  \"req_error\": true,\\n  \"json_validation_error\": false\\n}',\n",
       " 'ai-forever/rugpt3small_based_on_gpt2': '{\\n  \"scenes\": {},\\n  \"time\": 3.28,\\n  \"req_error\": true,\\n  \"json_validation_error\": false\\n}',\n",
       " 'bigcode/octocoder': '{\\n  \"scenes\": {},\\n  \"time\": 2.77,\\n  \"req_error\": true,\\n  \"json_validation_error\": false\\n}',\n",
       " 'bigcode/santacoder': '{\\n  \"scenes\": {},\\n  \"time\": 1.43,\\n  \"req_error\": true,\\n  \"json_validation_error\": false\\n}',\n",
       " 'bigcode/starcoder': '{\\n  \"scenes\": {},\\n  \"time\": 1.74,\\n  \"req_error\": true,\\n  \"json_validation_error\": false\\n}',\n",
       " 'bigcode/starcoder2-15b': '{\\n  \"scenes\": {},\\n  \"time\": 1.54,\\n  \"req_error\": true,\\n  \"json_validation_error\": false\\n}',\n",
       " 'bigcode/starcoder2-3b': '{\\n  \"scenes\": {},\\n  \"time\": 3.17,\\n  \"req_error\": true,\\n  \"json_validation_error\": false\\n}',\n",
       " 'bigcode/starcoderplus': '{\\n  \"scenes\": {},\\n  \"time\": 17.2,\\n  \"req_error\": true,\\n  \"json_validation_error\": false\\n}',\n",
       " 'codellama/CodeLlama-13b-hf': '{\\n  \"scenes\": {},\\n  \"time\": 3.16,\\n  \"req_error\": true,\\n  \"json_validation_error\": false\\n}',\n",
       " 'codellama/CodeLlama-34b-Instruct-hf': '{\\n  \"scenes\": {},\\n  \"time\": 1.35,\\n  \"req_error\": true,\\n  \"json_validation_error\": false\\n}',\n",
       " 'codellama/CodeLlama-7b-hf': '{\\n  \"scenes\": {},\\n  \"time\": 2.56,\\n  \"req_error\": true,\\n  \"json_validation_error\": false\\n}',\n",
       " 'CohereForAI/aya-23-35B': '{\\n  \"scenes\": {},\\n  \"time\": 1.54,\\n  \"req_error\": true,\\n  \"json_validation_error\": false\\n}',\n",
       " 'CohereForAI/c4ai-command-r-plus-08-2024': '{\\n  \"scenes\": {},\\n  \"time\": 1.64,\\n  \"req_error\": true,\\n  \"json_validation_error\": false\\n}',\n",
       " 'deepseek-ai/DeepSeek-Coder-V2-Instruct': '{\\n  \"scenes\": {},\\n  \"time\": 1.84,\\n  \"req_error\": true,\\n  \"json_validation_error\": false\\n}',\n",
       " 'deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B': '{\\n  \"scenes\": {},\\n  \"time\": 1.44,\\n  \"req_error\": true,\\n  \"json_validation_error\": false\\n}',\n",
       " 'deepseek-ai/DeepSeek-R1-Distill-Qwen-32B': '{\\n  \"scenes\": {},\\n  \"time\": 1.6,\\n  \"req_error\": true,\\n  \"json_validation_error\": false\\n}',\n",
       " 'distilbert/distilgpt2': '{\\n  \"scenes\": {},\\n  \"time\": 1.57,\\n  \"req_error\": true,\\n  \"json_validation_error\": false\\n}',\n",
       " 'EleutherAI/gpt-neo-1.3B': '{\\n  \"scenes\": {},\\n  \"time\": 19.77,\\n  \"req_error\": true,\\n  \"json_validation_error\": false\\n}',\n",
       " 'EleutherAI/gpt-neo-2.7B': '{\\n  \"scenes\": {},\\n  \"time\": 3.58,\\n  \"req_error\": true,\\n  \"json_validation_error\": false\\n}',\n",
       " 'EleutherAI/gpt-neox-20b': '{\\n  \"scenes\": {},\\n  \"time\": 2.97,\\n  \"req_error\": true,\\n  \"json_validation_error\": false\\n}',\n",
       " 'google/gemma-1.1-2b-it': '{\\n  \"scenes\": {},\\n  \"time\": 1.84,\\n  \"req_error\": true,\\n  \"json_validation_error\": false\\n}',\n",
       " 'google/gemma-1.1-7b-it': '{\\n  \"scenes\": {},\\n  \"time\": 1.95,\\n  \"req_error\": true,\\n  \"json_validation_error\": false\\n}',\n",
       " 'google/gemma-2-27b-it': '{\\n  \"scenes\": {},\\n  \"time\": 2.05,\\n  \"req_error\": true,\\n  \"json_validation_error\": false\\n}',\n",
       " 'google/gemma-2-2b-it': '{\\n  \"scenes\": {},\\n  \"time\": 1.74,\\n  \"req_error\": true,\\n  \"json_validation_error\": false\\n}',\n",
       " 'google/gemma-2-9b-it': '{\\n  \"scenes\": {},\\n  \"time\": 1.64,\\n  \"req_error\": true,\\n  \"json_validation_error\": false\\n}',\n",
       " 'google/gemma-2b': '{\\n  \"scenes\": {},\\n  \"time\": 4.71,\\n  \"req_error\": true,\\n  \"json_validation_error\": false\\n}',\n",
       " 'google/gemma-7b': '{\\n  \"scenes\": {},\\n  \"time\": 7.07,\\n  \"req_error\": true,\\n  \"json_validation_error\": false\\n}',\n",
       " 'Gustavosta/MagicPrompt-Stable-Diffusion': '{\\n  \"scenes\": {},\\n  \"time\": 2.25,\\n  \"req_error\": true,\\n  \"json_validation_error\": false\\n}',\n",
       " 'HuggingFaceH4/starchat-beta': '{\\n  \"scenes\": {},\\n  \"time\": 1.95,\\n  \"req_error\": true,\\n  \"json_validation_error\": false\\n}',\n",
       " 'HuggingFaceH4/starchat2-15b-v0.1': '{\\n  \"scenes\": {},\\n  \"time\": 1.74,\\n  \"req_error\": true,\\n  \"json_validation_error\": false\\n}',\n",
       " 'HuggingFaceH4/zephyr-7b-alpha': '{\\n  \"scenes\": {},\\n  \"time\": 1.67,\\n  \"req_error\": true,\\n  \"json_validation_error\": false\\n}',\n",
       " 'HuggingFaceH4/zephyr-7b-beta': '{\\n  \"scenes\": {},\\n  \"time\": 1.91,\\n  \"req_error\": true,\\n  \"json_validation_error\": false\\n}',\n",
       " 'HuggingFaceM4/idefics-9b-instruct': '{\\n  \"scenes\": {},\\n  \"time\": 1.76,\\n  \"req_error\": true,\\n  \"json_validation_error\": false\\n}',\n",
       " 'HuggingFaceM4/idefics2-8b': '{\\n  \"scenes\": {},\\n  \"time\": 1.62,\\n  \"req_error\": true,\\n  \"json_validation_error\": false\\n}',\n",
       " 'jinaai/reader-lm-1.5b': '{\\n  \"scenes\": {},\\n  \"time\": 1.78,\\n  \"req_error\": true,\\n  \"json_validation_error\": false\\n}',\n",
       " 'meta-llama/Llama-2-13b-chat-hf': '{\\n  \"scenes\": {},\\n  \"time\": 1.38,\\n  \"req_error\": true,\\n  \"json_validation_error\": false\\n}',\n",
       " 'meta-llama/Llama-2-70b-chat-hf': '{\\n  \"scenes\": {},\\n  \"time\": 1.44,\\n  \"req_error\": true,\\n  \"json_validation_error\": false\\n}',\n",
       " 'meta-llama/Llama-2-7b-chat-hf': '{\\n  \"scenes\": {},\\n  \"time\": 1.64,\\n  \"req_error\": true,\\n  \"json_validation_error\": false\\n}',\n",
       " 'meta-llama/Llama-3.1-70B-Instruct': '{\\n  \"scenes\": {},\\n  \"time\": 1.53,\\n  \"req_error\": true,\\n  \"json_validation_error\": false\\n}',\n",
       " 'meta-llama/Llama-3.1-8B-Instruct': '{\\n  \"scenes\": {},\\n  \"time\": 1.74,\\n  \"req_error\": true,\\n  \"json_validation_error\": false\\n}',\n",
       " 'meta-llama/Llama-Guard-3-8B': '{\\n  \"scenes\": {},\\n  \"time\": 1.85,\\n  \"req_error\": true,\\n  \"json_validation_error\": false\\n}',\n",
       " 'microsoft/Phi-3-mini-128k-instruct': '{\\n  \"scenes\": {},\\n  \"time\": 1.94,\\n  \"req_error\": true,\\n  \"json_validation_error\": false\\n}',\n",
       " 'microsoft/Phi-3-mini-4k-instruct': '{\\n  \"scenes\": {},\\n  \"time\": 1.84,\\n  \"req_error\": true,\\n  \"json_validation_error\": false\\n}',\n",
       " 'mistralai/Mistral-7B-Instruct-v0.1': '{\\n  \"scenes\": {},\\n  \"time\": 2.87,\\n  \"req_error\": true,\\n  \"json_validation_error\": false\\n}',\n",
       " 'mistralai/Mistral-7B-v0.1': '{\\n  \"scenes\": {},\\n  \"time\": 2.45,\\n  \"req_error\": true,\\n  \"json_validation_error\": false\\n}',\n",
       " 'NousResearch/Hermes-3-Llama-3.1-8B': '{\\n  \"scenes\": {},\\n  \"time\": 1.84,\\n  \"req_error\": true,\\n  \"json_validation_error\": false\\n}',\n",
       " 'openai-community/gpt2': '{\\n  \"scenes\": {},\\n  \"time\": 1.91,\\n  \"req_error\": true,\\n  \"json_validation_error\": false\\n}',\n",
       " 'Qwen/Qwen2.5-72B-Instruct': '{\\n  \"scenes\": {},\\n  \"time\": 1.57,\\n  \"req_error\": true,\\n  \"json_validation_error\": false\\n}',\n",
       " 'tiiuae/falcon-7b-instruct': '{\\n  \"scenes\": {},\\n  \"time\": 1.84,\\n  \"req_error\": true,\\n  \"json_validation_error\": false\\n}',\n",
       " 'deepseek-ai/DeepSeek-R1-Distill-Llama-8B': '{\\n  \"scenes\": {},\\n  \"time\": 1.64,\\n  \"req_error\": true,\\n  \"json_validation_error\": false\\n}',\n",
       " 'deepseek-ai/DeepSeek-R1-Distill-Qwen-7B': '{\\n  \"scenes\": {},\\n  \"time\": 2.14,\\n  \"req_error\": true,\\n  \"json_validation_error\": false\\n}',\n",
       " 'deepseek-ai/DeepSeek-R1-Distill-Qwen-14B': '{\\n  \"scenes\": {},\\n  \"time\": 2.15,\\n  \"req_error\": true,\\n  \"json_validation_error\": false\\n}'}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'scenes': {}, 'time': 1.57, 'req_error': True, 'json_validation_error': False}\n",
      "{'scenes': {}, 'time': 1.62, 'req_error': True, 'json_validation_error': False}\n",
      "{'scenes': {}, 'time': 3.28, 'req_error': True, 'json_validation_error': False}\n",
      "{'scenes': {}, 'time': 2.77, 'req_error': True, 'json_validation_error': False}\n",
      "{'scenes': {}, 'time': 1.43, 'req_error': True, 'json_validation_error': False}\n",
      "{'scenes': {}, 'time': 1.74, 'req_error': True, 'json_validation_error': False}\n",
      "{'scenes': {}, 'time': 1.54, 'req_error': True, 'json_validation_error': False}\n",
      "{'scenes': {}, 'time': 3.17, 'req_error': True, 'json_validation_error': False}\n",
      "{'scenes': {}, 'time': 17.2, 'req_error': True, 'json_validation_error': False}\n",
      "{'scenes': {}, 'time': 3.16, 'req_error': True, 'json_validation_error': False}\n",
      "{'scenes': {}, 'time': 1.35, 'req_error': True, 'json_validation_error': False}\n",
      "{'scenes': {}, 'time': 2.56, 'req_error': True, 'json_validation_error': False}\n",
      "{'scenes': {}, 'time': 1.54, 'req_error': True, 'json_validation_error': False}\n",
      "{'scenes': {}, 'time': 1.64, 'req_error': True, 'json_validation_error': False}\n",
      "{'scenes': {}, 'time': 1.84, 'req_error': True, 'json_validation_error': False}\n",
      "{'scenes': {}, 'time': 1.44, 'req_error': True, 'json_validation_error': False}\n",
      "{'scenes': {}, 'time': 1.6, 'req_error': True, 'json_validation_error': False}\n",
      "{'scenes': {}, 'time': 1.57, 'req_error': True, 'json_validation_error': False}\n",
      "{'scenes': {}, 'time': 19.77, 'req_error': True, 'json_validation_error': False}\n",
      "{'scenes': {}, 'time': 3.58, 'req_error': True, 'json_validation_error': False}\n",
      "{'scenes': {}, 'time': 2.97, 'req_error': True, 'json_validation_error': False}\n",
      "{'scenes': {}, 'time': 1.84, 'req_error': True, 'json_validation_error': False}\n",
      "{'scenes': {}, 'time': 1.95, 'req_error': True, 'json_validation_error': False}\n",
      "{'scenes': {}, 'time': 2.05, 'req_error': True, 'json_validation_error': False}\n",
      "{'scenes': {}, 'time': 1.74, 'req_error': True, 'json_validation_error': False}\n",
      "{'scenes': {}, 'time': 1.64, 'req_error': True, 'json_validation_error': False}\n",
      "{'scenes': {}, 'time': 4.71, 'req_error': True, 'json_validation_error': False}\n",
      "{'scenes': {}, 'time': 7.07, 'req_error': True, 'json_validation_error': False}\n",
      "{'scenes': {}, 'time': 2.25, 'req_error': True, 'json_validation_error': False}\n",
      "{'scenes': {}, 'time': 1.95, 'req_error': True, 'json_validation_error': False}\n",
      "{'scenes': {}, 'time': 1.74, 'req_error': True, 'json_validation_error': False}\n",
      "{'scenes': {}, 'time': 1.67, 'req_error': True, 'json_validation_error': False}\n",
      "{'scenes': {}, 'time': 1.91, 'req_error': True, 'json_validation_error': False}\n",
      "{'scenes': {}, 'time': 1.76, 'req_error': True, 'json_validation_error': False}\n",
      "{'scenes': {}, 'time': 1.62, 'req_error': True, 'json_validation_error': False}\n",
      "{'scenes': {}, 'time': 1.78, 'req_error': True, 'json_validation_error': False}\n",
      "{'scenes': {}, 'time': 1.38, 'req_error': True, 'json_validation_error': False}\n",
      "{'scenes': {}, 'time': 1.44, 'req_error': True, 'json_validation_error': False}\n",
      "{'scenes': {}, 'time': 1.64, 'req_error': True, 'json_validation_error': False}\n",
      "{'scenes': {}, 'time': 1.53, 'req_error': True, 'json_validation_error': False}\n",
      "{'scenes': {}, 'time': 1.74, 'req_error': True, 'json_validation_error': False}\n",
      "{'scenes': {}, 'time': 1.85, 'req_error': True, 'json_validation_error': False}\n",
      "{'scenes': {}, 'time': 1.94, 'req_error': True, 'json_validation_error': False}\n",
      "{'scenes': {}, 'time': 1.84, 'req_error': True, 'json_validation_error': False}\n",
      "{'scenes': {}, 'time': 2.87, 'req_error': True, 'json_validation_error': False}\n",
      "{'scenes': {}, 'time': 2.45, 'req_error': True, 'json_validation_error': False}\n",
      "{'scenes': {}, 'time': 1.84, 'req_error': True, 'json_validation_error': False}\n",
      "{'scenes': {}, 'time': 1.91, 'req_error': True, 'json_validation_error': False}\n",
      "{'scenes': {}, 'time': 1.57, 'req_error': True, 'json_validation_error': False}\n",
      "{'scenes': {}, 'time': 1.84, 'req_error': True, 'json_validation_error': False}\n",
      "{'scenes': {}, 'time': 1.64, 'req_error': True, 'json_validation_error': False}\n",
      "{'scenes': {}, 'time': 2.14, 'req_error': True, 'json_validation_error': False}\n",
      "{'scenes': {}, 'time': 2.15, 'req_error': True, 'json_validation_error': False}\n"
     ]
    }
   ],
   "source": [
    "for key,val in llm_output.items():\n",
    "    val=read_json(val)\n",
    "    print(val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "book",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
